{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This script is just trying to determine if a item is in GEAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports for libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "input_file = \"service_now_sample.csv\"\n",
    "# can do the yes to 1 in read_csv\n",
    "df = pd.read_csv(input_file, header = 0)\n",
    "original_headers = list(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['line', 'TCO_Approach', 'u_category_gear', 'ServiceNow_C-S-I-D Analysis_Determine_GEAR_Category', 'u_category', 'U_Category_Match', 'u_subcategory', 'U_SubCategory_Match', 'u_item', 'U_Item_Match', 'short_description', 'caller_id.company', 'assignment_group.parent', 'assignment_group', 'number', 'opened_at', 'u_resolved', 'calendar_duration_days', 'location', 'incident_state', 'priority', 'parent_incident', 'contact_type', 'impact']\n"
     ]
    }
   ],
   "source": [
    "print(original_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only need `short_description` and `U_Category_Match` as dependent variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lindsayyoung/.local/share/virtualenvs/tbm_ml-Epu1yQDw/lib/python3.6/site-packages/pandas/core/generic.py:4619: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "gear_df = df[['short_description', 'U_Category_Match']]\n",
    "# make\n",
    "gear_df.U_Category_Match.replace(('Yes', 'No', ''), (1, 0, 0), inplace=True)\n",
    "gear_df = gear_df.replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       short_description  U_Category_Match\n",
      "0                               Issue getting into Aloha               0.0\n",
      "1                                                  Aloha               0.0\n",
      "2                  Aloha prompting for two-factor login.               0.0\n",
      "3                              Aloha login 403 forbidden               0.0\n",
      "4                              Aloha appears to be down?               0.0\n",
      "5        *** PARENT TICKET  ***aloha.gsa.gov login issue               0.0\n",
      "6      *** CHILD TICKET to INC2239534 ***aloha.gsa.go...               0.0\n",
      "7                                      aloha login issue               0.0\n",
      "8                                            Aloha Login               0.0\n",
      "9                                            Aloha issue               0.0\n",
      "10          ALOHA - Message Undeliverable after Amending               0.0\n",
      "11                                Unable to Access ALOHA               0.0\n",
      "12                         Aloha not updating from ETAMS               1.0\n",
      "13                                       eTams Amendment               1.0\n",
      "14                                Aloha - ETAMS Mismatch               1.0\n",
      "15                                   ALOHA Reconcilation               1.0\n",
      "16                                      Amend Timecard -               1.0\n",
      "17                               Cannot Approve Requests               1.0\n",
      "18                             ALOHA Additional Approver               1.0\n",
      "19                                            aloha jury               1.0\n",
      "20                 Regardiang amendments and application               1.0\n",
      "21                                                 ALOHA               1.0\n",
      "22                           Supervisor Missing in Aloha               1.0\n",
      "23                  ALOHA - How to Change Leave Approver               1.0\n",
      "24                   Supervisor List Needs to be Revised               1.0\n",
      "25                                   Supervisor Addition               1.0\n",
      "26                               Aloha past year changes               1.0\n",
      "27                                    ALOHA Add Approver               1.0\n",
      "28            Supervisor:  Bill Stroumbaras or Tom Lyman               1.0\n",
      "29     ALOHA - User needs to withdraw 3 leave request...               1.0\n",
      "...                                                  ...               ...\n",
      "83903                                         vdi log in               0.0\n",
      "83904                         Question about remoting in               0.0\n",
      "83905                           How to log into Horizon.               0.0\n",
      "83906  Unable to access horizon.gsa.gov.  Error: acce...               0.0\n",
      "83907       How to get into VDI from a non-GSA computer.               0.0\n",
      "83908                  Share drive access in VDI session               0.0\n",
      "83909                                 MS word doc locked               0.0\n",
      "83910                    Horizon login and functionality               0.0\n",
      "83911                                      File Recovery               0.0\n",
      "83912           Virtual Desktop (VDI) Login Instructions               0.0\n",
      "83913                               Unable to access VDI               0.0\n",
      "83914                             How to use VDI Horizon               0.0\n",
      "83915                    Questions about the VDI system.               0.0\n",
      "83916                                    Horizon install               0.0\n",
      "83917                               Lockedout of horizon               0.0\n",
      "83918                                     Horizon Access               0.0\n",
      "83919                VDI - Assistance with installation.               0.0\n",
      "83920               user needs help logging into horizon               0.0\n",
      "83921           Assistance with VM Horizon installation.               0.0\n",
      "83922                                        VDI Horizon               0.0\n",
      "83923  How to get OTP for logging into Horizon on a p...               0.0\n",
      "83924                    cannot access drives in horizon               0.0\n",
      "83925                               horizon log in issue               0.0\n",
      "83926         how to update horizon on personal computer               0.0\n",
      "83927                                     horizon log in               0.0\n",
      "83928                                     Horizon Access               0.0\n",
      "83929                                          VDI issue               0.0\n",
      "83930                                         VDI Access               0.0\n",
      "83931                                  Accessing horizon               0.0\n",
      "83932                                             SoapUI               0.0\n",
      "\n",
      "[83933 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(gear_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83933, 21967)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(stop_words='english')\n",
    "X_train_counts = count_vect.fit_transform(gear_df['short_description'].values)\n",
    "X_train_counts.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4046)\t1\n",
      "  (0, 9975)\t1\n",
      "  (0, 11924)\t1\n",
      "  (1, 4046)\t1\n",
      "  (2, 12950)\t1\n",
      "  (2, 9116)\t1\n",
      "  (2, 15704)\t1\n",
      "  (2, 4046)\t1\n",
      "  (3, 9492)\t1\n",
      "  (3, 1896)\t1\n",
      "  (3, 12950)\t1\n",
      "  (3, 4046)\t1\n",
      "  (4, 4251)\t1\n",
      "  (4, 4046)\t1\n",
      "  (5, 10113)\t1\n",
      "  (5, 10506)\t1\n",
      "  (5, 19818)\t1\n",
      "  (5, 14918)\t1\n",
      "  (5, 12950)\t1\n",
      "  (5, 4046)\t1\n",
      "  (5, 11924)\t1\n",
      "  (6, 11584)\t1\n",
      "  (6, 5842)\t1\n",
      "  (6, 10113)\t1\n",
      "  (6, 10506)\t1\n",
      "  :\t:\n",
      "  (83923, 15024)\t1\n",
      "  (83923, 15164)\t1\n",
      "  (83923, 10993)\t1\n",
      "  (83923, 12946)\t1\n",
      "  (83924, 7840)\t1\n",
      "  (83924, 10993)\t1\n",
      "  (83924, 3703)\t1\n",
      "  (83925, 10993)\t1\n",
      "  (83925, 12939)\t1\n",
      "  (83925, 11924)\t1\n",
      "  (83926, 15164)\t1\n",
      "  (83926, 10993)\t1\n",
      "  (83926, 6514)\t1\n",
      "  (83926, 20484)\t1\n",
      "  (83927, 10993)\t1\n",
      "  (83927, 12939)\t1\n",
      "  (83928, 10993)\t1\n",
      "  (83928, 3703)\t1\n",
      "  (83929, 21126)\t1\n",
      "  (83929, 11924)\t1\n",
      "  (83930, 21126)\t1\n",
      "  (83930, 3703)\t1\n",
      "  (83931, 10993)\t1\n",
      "  (83931, 3711)\t1\n",
      "  (83932, 18265)\t1\n"
     ]
    }
   ],
   "source": [
    "print(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83933, 21967)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lindsayyoung/.local/share/virtualenvs/tbm_ml-Epu1yQDw/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-e5ac90569bf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mformated_category\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgear_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'U_Category_Match'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_counts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformated_category\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/tbm_ml-Epu1yQDw/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \"\"\"\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/tbm_ml-Epu1yQDw/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/tbm_ml-Epu1yQDw/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 44\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "formated_category = gear_df[['U_Category_Match']]\n",
    "clf = MultinomialNB().fit(X_train_counts, formated_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
